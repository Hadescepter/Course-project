epoch,loss,grad_norm,learning_rate
0.08,2.8138,1.439,0.00019285714285714286
0.16,1.9298,0.8076,0.00018492063492063493
0.24,1.8411,0.6897,0.00017698412698412697
0.32,1.7959,0.802,0.00016904761904761904
0.4,1.7801,0.7458,0.0001611111111111111
0.48,1.7631,0.8408,0.00015317460317460318
0.56,1.6732,0.8489,0.00014523809523809525
0.64,1.6496,0.8823,0.00013730158730158732
0.72,1.7114,0.8232,0.0001293650793650794
0.8,1.578,0.8938,0.00012142857142857143
0.88,1.6245,0.8216,0.0001134920634920635
0.96,1.6451,0.9628,0.00010555555555555557
1.03,1.5414,0.8986,9.761904761904762e-05
1.11,1.5239,1.1188,8.968253968253969e-05
1.19,1.537,0.9934,8.174603174603175e-05
1.27,1.501,0.9804,7.380952380952382e-05
1.35,1.5301,1.0691,6.587301587301587e-05
1.43,1.471,1.1309,5.793650793650795e-05
1.51,1.5426,1.1883,5e-05
1.59,1.4453,1.0049,4.2063492063492065e-05
1.67,1.5075,1.1199,3.412698412698413e-05
1.75,1.4667,1.0636,2.6190476190476192e-05
1.83,1.5274,0.9906,1.8253968253968254e-05
1.91,1.478,0.9667,1.0317460317460318e-05
1.99,1.4292,1.0684,2.3809523809523808e-06
